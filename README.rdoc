= Motivation

We needed a way to provide automated failover on various systems 
where we don't have access to virtual IPs.

= Goals

* Failover via /etc/hosts.
* Perform ANY auxiliary duties necessary for a successful failover. (restart job servers, web servers, hang maintenance page, etc..)
* Monitor the status of the entire failover system and report to Nagios.
* Perform or reset the failover manually from the command line.

= Overview

== Plugin Architecture

Since there are guaranteed to be edge cases deadpool was designed to utilize
additional custom plugins from the config directory.  Examples are created 
for you by the deadpool_generator command.


== Chainable Failover Protocols

deadpool can take any number of FailoverProtocols
and execute them in succession in the event of a failover.  Such as 
restarting nginx after making a change to /etc/hosts.


== Multiple Services

Multiple services (ex. mysql, redis, production, staging, etc...) can be
configured under a single instance by putting them all in the same config directory.
Multiple instances can be configured to run on a single box by specifying a separate
configuration directory and admin port for each instance.


== Monitoring

deadpool can test each point in the system and report
when something is out of place.  Meaning it tests more than MySQL, it tests
that all the app servers are pointing at the correct MySQL server and that it has
write permission on /etc/hosts and so on.


    $ deadpool_admin --nagios_report
    OK -  last checked 12 seconds ago.


    $ deadpool_admin --full_report
    System Status: OK

    Deadpool::Server - 
    OK - checked 3 seconds ago.

      production_database - Deadpool::Handler
      OK - checked 5 seconds ago.
      Primary Check OK.

         - Deadpool::Monitor::Mysql
        OK - checked 3 seconds ago.
        Primary and Secondary are up.

         - Deadpool::FailoverProtocol::EtcHosts
        OK - checked 2 seconds ago.
        Write check passed all servers: 10.1.2.3, 10.1.2.4
        All client hosts are pointed at the primary.

         - Deadpool::FailoverProtocol::ExecRemoteCommand
        OK - checked 2 seconds ago.
        Exec test passed all servers: 10.1.2.3, 10.1.2.4


== How it works

It periodically checks that the primary is okay at an interval of your
choosing. When the primary check has failed enough times in a row to exceed
your threshold it will execute the failover protocol. The failover
protocol is just a list of failover protocols in order. Generally each one
will perform a preflight check first. As each one finishes the failover it
records it's state and success or failure. Once it's all done, deadpool locks
the state so an admin can see what happened and if there were any issues along
the way.

Currently deadpool is a single bullet gun. Once it's failed over, it's done. 
It can perform a manual promotion from the command line but it will have to be
restarted to work again.  This may change in a future release.


= Installation

== Deadpool Server
    $ gem install deadpool
    $ sudo deadpool_generator --configuration
    $ sudo deadpool_generator --upstart_init

== App Server
    $ gem install deadpool
    $ sudo adduser deadpool
    $ sudo chgrp deadpool /etc/hosts
    $ sudo chmod 664 /etc/hosts
    $ which deadpool_hosts

= Configuration

  pool_name: 'production_database'
  check_interval: 3
  max_failed_checks: 10
  primary_host:   10.x.x.x
  secondary_host: 10.x.x.x

  monitor_config:
    monitor_class: Mysql
    name: 'Database Monitor'
    nagios_plugin_path: '/usr/lib/nagios/plugins/check_mysql'
    username: 'db_admin'
    password: 'passwerd'

  failover_protocol_configs:
    - protocol_class: EtcHosts
      name: 'Change Hosts'
      script_path: '/usr/local/bin/deadpool_hosts'
      service_host_name: 'unique.production.database.name'
      username: 'deadpool'
      password: 'passwerd'
      client_hosts:
        - '10.x.x.x' # app1
        - '10.x.x.x' # app2
        - '10.x.x.x' # app3
        - '10.x.x.x' # app4
        - '10.x.x.x' # jobserver

    - protocol_class: ExecRemoteCommand
      name: 'Restart Nginx'
      test_command: '/etc/init.d/nginx status'
      exec_command: '/etc/init.d/nginx restart'
      username: 'deadpool'
      password: 'passwerd'
      client_hosts:
        - '10.x.x.x' # app1
        - '10.x.x.x' # app2
        - '10.x.x.x' # app3
        - '10.x.x.x' # app4

    - protocol_class: ExecRemoteCommand
      name: 'Restart Job Service'
      test_command: '/etc/init.d/monit test'
      exec_command: '/etc/init.d/monit restart'
      username: 'deadpool'
      password: 'passwerd'
      use_sudo: 1
      client_hosts:
        - '10.x.x.x' # jobserver


== Putting it all together

Once it's installed, configured and running you should be able to get 
the status of the system by running asking deadpool_admin for a full report.

  $ deadpool_admin --full_report
  
If the server is up and it can write to the /etc/hosts file on all the app 
servers you can use the following command to add the new entry to 
/etc/hosts on all your app servers.

  $ deadpool_admin --promote_server --server=primary_host --pool=production_database
  $ deadpool_admin --full_report

If deadpool reports everything is okay you can now connect it to Nagios via 
the built in Nagios reporting flag.  Keep in mind that for the Nagios check 
is cached from the last system check.  --full_report is not cached.

  $ deadpool_admin --nagios_report
  OK -  last checked 16 seconds ago.
  

If deadpool reports check out OK then you should be ready for primetime.  
You can configure your app to connect to the database via the 
service_host_name (unique.production.database.name according to the 
above config example).



